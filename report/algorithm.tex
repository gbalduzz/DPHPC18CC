\mypar{Connected components}
%Precisely define sorting problem you consider.
%\mypar{Sorting algorithms}
%Explain the algorithm you use including their costs.
%
%As an aside, don't talk about "the complexity of the algorithm.'' It's incorrect,
%problems have a complexity, not algorithms.

For an unordered graph $G=(V,E)$, the connected components are the ensemble
of connected subgraphs, where connected means that for any two  vertices, there exist a path along the
 edges connecting them.
The straightforward algorithm to find them is to perform either a breath or depth first search from a starting
random vertex in $V$, and give the same label to all the touched vertices. Then repeat the search from an unlabelled vertex
until there are no more left.
This has a cost in terms of memory accesses of $\Theta(\abs{E} + \abs{V})$, which turns to be optimal \cite{Hopcroft}.

\section{Proposed Algorithm}\label{sec:yourmethod}
%Now comes the ``beef'' of the report, where you explain what you
%did. Again, organize it in paragraphs with titles. As in every section
%you start with a very brief overview of the section.
%
%In this section, structure is very important so one can follow the technical content.
%
%Mention and cite any external resources that you used including libraries or other code.

Unfortunately this algorithm does not parallelize straightforwardly. Pavel Tvrdik \cite{PCompClass}
proposed to cast the problem in terms of the generation of a forest, where the vertices of the same connected comonent belong
to the same three, and its root can be used as the representative.
We defining a star as a three of height one, a singleton a tree with a single element, and use the variables
 $n=\abs{V}$ and $m=\abs{E}$.
His algorithm can be summarized as:

\begin{algorithm}%[H]
    \caption{Pavel Tvrdik's Connected components}
    \label{algorithm:cc1}
    \begin{algorithmic}[1]
        \Procedure{Hook}{$i, j$}
          \State $p[p[i]] = p[j]$
        \EndProcedure
        \Procedure{connectedComponents}{$n, \text{edges}$}
          \State $p[i] = i \quad \forall i \in \{1,\cdots, n\}$. \Comment{Initialize a list of parents.}
        \While{Elements of $p$ are changed.}
        \For{$\left<i, j\right> \in \text{edges}$} \Comment{Execute in parallel.}
          \State  \kif $i\ge j$ \kthen Hook($i, j$)
          \State  \kif $\text{isSingleton}(i)$ \kthen Hook($i, j$)
        \EndFor
        \For{$\left<i, j\right> \in \text{edges}$} \Comment{Execute in parallel.}
          \State  \kif isStar(i) \kand $i \neq j$ \kthen Hook($i, j$)
        \EndFor
        \State $p[i] = \text{root}(i) \quad \forall i \in \{1,\cdots, n\}$ \Comment{Compress the forest in parallel.}
        \EndWhile
        \EndProcedure
   \end{algorithmic}
\end{algorithm}
We defer to \cite{PCompClass} for a proof of correctness.

After implementing this algorithm we found advantageous to remove the constraint
that only singletons and stars can be hooked to another vertex, so that only a single pass through
the edge list is required. Extra care is then required during parallel execution: as each vertex has only one outgoing
connection, we need to avoid that a process overwrites a connection that has been formed by another one.
We therefore need to grow our forest with the following rules:

\begin{enumerate}
    \item A hook must originate from a vertex id higher than the destination.
    \item All edges must generate a connection between the relative vertices, or vertices at an higher level in their three.
    \item A hook must originate from a vertex that is currently the root of a tree.
\end{enumerate}

The intuitive proof of correctness follows: rule $1$ means that the graph gebnerated by the
hooks generate a directed graph with no cycles and with at most a single outgoing connection, therefore it must be a forest.
Rule $2$ and $3$ enforce that after processing an edge between two nodes,
they belong to the same tree, and rule $3$ guarantees that this connection can not be broken by a different edge.
At the end of the algorithm, by following the connections from each vertex to the root, we can find a representative for each connected component.

To implement rule $3$ in a multithreaded environment, we use an atomic compare and swap.
We compare the parent of the hook's origin with its id, if they match it means the vertex is still a root and we
hook we hook it to its destination. It does not matter for correctness if the destination is a root, but we try withouth enforcing to
hook to a root to minimize the three height.
We found empirically that using \verb|std::atomic_compare_exchange_weak|,
compared to \verb|std::atomic_compare_exchange_strong| offers better performance, as we anyway need to loop until a hook is successful.


In pseudocode our algorithm is:

\begin{algorithm}%[H]
    \caption{Proposed algorithm}
    \label{algorithm:cc2}
    \begin{algorithmic}[1]
        \Procedure{connectedComponents}{$n, \text{edges}$}
        \State $p[i] = i \quad \forall i \in \{1,\cdots, n\}$. %\Comment{Initialize a list of parents.}
        \For{$\left<i, j\right> \in \text{edges}$} \Comment{Execute in parallel.}
        \While{hook is not successful.}
                \State from = max(root(i), root(j))
                \State to = mint(root(i), root(j))
                \State  atomicHook(from, to)
        \EndWhile
        \State  \kif !isRoot(i) \kthen p[i] = root(i) \label{algorithm:step:skip_connection}
        \State  \kif !isRoot(j) \kthen p[j] = root(j)
        \EndFor
        \State $p[i] = \text{root}(i) \quad \forall i \in \{1,\cdots, n\}$ \Comment{Compress the forest in parallel.}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

While the step \ref{algorithm:step:skip_connection} is not necessary for correctness, we found that
reusing the already computed vertex's representative leads to a smaller tree height. This and the parallel compression works and was tested to
be efficient only on architectures such as x86, where writes to 32 or 64-bits variables storing a label are atomic.

The overall cost of the algorithm is $\Theta((n + m)\langle H \rangle)$, where $\langle H \rangle$ is
the average tree height. Theefore $\langle H \rangle = \Theta(1)$ for a subcritical random graph, and on average (relatively to the execution order of the loop) $\langle H \rangle = \Theta(\log(n))$
for a supercrital one \cite{RandomGraph}.

\mypar{Multiple compute nodes}


