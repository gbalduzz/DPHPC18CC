

\mypar {Motivation}
\replaced{Problems in computer science are often modeled as graphs.}{In computer science problems often get model as graphs and} Therefore, graph algorithms are ubiquitous. One of these graph problems is \deleted{the task of} finding \deleted{the} connected components in a graph. It is a well understood problem in graph theory with a variety of applicable domains. Computer vision tasks, such as pattern recognition and image segmentation \cite{683775} can make use of connected components \cite{Wilson:2006:RCV:1166253.1166292}. Other fields are medical imaging \cite{UDUPA1990355} and image processing \cite{Ambrosio2001}. \replaced{The related problem of strongly connected components will not be discussed in this paper}{We will not discuss the related problem of strongly connected components}.

\deleted{As already mentioned this problem is well-studied both sequentially and in parallel.} The first sequential algorithm \added{to solve the connected components problem} goes back to \cite{Hopcroft}. \deleted{A few} Parallel approaches \deleted{would be} \added{were presented in }\cite{MANOHAR1989133} \added{and} \cite{Han:1990:EFP:79147.214077} \added{.} \deleted{and} Recently \cite{comm_avoiding} \added{was published,} where \deleted{they used} a communication-avoiding approach \added{was discussed}. A communication-avoiding algorithm uses asymptotically less communication. By doing so \cite{comm_avoiding} sacrifices some \added{computational} efficiency \deleted{in the computation} as the root node does most of the work. \replaced{In this paper we present an algorithm which distributes the work while still avoiding as much communication as possible. This is achieved my distributing the list of edges evenly among different MPI processes. These then locally compute their corresponding connected components which are represented as a forest. In the next step the algorithm reduces these forests in a binary manner. Two processes compare and merge their results and then compress it, to reduce the heights of the trees. This step gets repeated until the final results gets propagated to the root process.

We then show a direct comparison of a pure MPI and a pure OMP implementation of this algorithm against the communication avoiding one on a set of very large graphs ($2\times10^8$ Edges and up to $2\times10^7$ Vertices) were the OMP version performs better than the others. We also show results from using a mixture of MPI and OMP. 

Finally we outline some future work that could be done to further improve the performance of this algorithm.
}{We wanted to improve on this by also introducing a distributed computation based on hooking \cite{article} and ignoring the communication part.} \deleted[remark=this does not belong in the motivation]{In a additional step we distributed the list of edges evenly among different MPI proccesses. This allows us to outperform the communication avoiding approach especially on denser graphs. Our approach perfroms significantly worse on a small amount of nodes (n$\leq$ 5) but as we increase the total number of cores the benefits of our algorithms starts to show.}

