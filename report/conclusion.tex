The proposed algorithm manages to take advantage of the parallelism available within shared memory units while avoiding excessive communication between them. By choosing the right number of OMP threads per MPI rank the algorithm achieves good scaling across a variety of graphs. The results show our algorithm outperforming the communication-avoiding algorithm \cite{comm_avoiding} in each experiment except for the densest graph on Euler.